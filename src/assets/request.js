import { ref } from 'vue'
import { saveAs } from 'file-saver'
import axios from 'axios'
import useAppInfo from '@/composables/useAppInfo'
import useServerInfo from '@/composables/useWSClient.js'

import { execute, path } from '../context.js'
const { dataUrl, datasetId, wsUrl } = useAppInfo()
const websock = useServerInfo(wsUrl)
// note : the id is obtained after a post, it's a random string generated by DataFair's API -> _id attribute of a POST reponse
export const dataset = ref(new Map()) // key : id of all current versions of files/folders, value: object of metadatas values
export const hmDisplay = ref([]) // represent the array of histoModif.get(current id)
export const loading = ref(false) // show a progress bar
export const loadingIndex = ref(false) // show a progress bar
export const percentage = ref(0) // value of the progress bar
export const displayError = ref(false) // display error v-snackbar if error on requests
export const errorMessage = ref('')
export const pathGED = ref([]) // key : id, value : name of the associated folder, it represents the navigation bar upon the data table
// method : post the document generated by the button
export async function postDocument (payload) {
  const { nom, file } = payload
  const url = `${dataUrl}/lines`
  if (file !== null && file.size < 5000000) { // we post a file
    if (path.value !== '/') { // first, check if the data we post is the first value of a fodler, if yes delete the folder
      const tmp = path.value.split('/')
      tmp.pop()
      const name = tmp.pop()
      tmp.push('')
      const str = tmp.join('\\/')
      const p = encodeURIComponent('path:/' + str + '/')
      const url2 = `${dataUrl}/lines?q=${name}&q_fields=nom&q_mode=simple&qs=${p} and type_mime:"_folder"`
      const request = await fetch(url2)
      if (request.ok) {
        const rep = await request.json()
        if (rep.results[0] !== undefined) {
          const id = rep.results[0]._id
          const url = `${dataUrl}/lines/${id}`
          const params = {
            method: 'DELETE',
            headers: {
              'Content-type': 'application/json'
            }
          }
          try {
            const metaData = await fetch(url, params)
            if (metaData.status === 204) {
            // faire qq chose
            }
          } catch (e) {
            errorMessage.value = e.response.status + ' : ' + e.response.data
            displayError.value = true
          }
        }
      }
    }
    const formData = new FormData()
    formData.append('attachment', file)
    formData.append('nom', nom || file.name)
    formData.append('nbrevisions', 1)
    formData.append('taille', file.size)
    formData.append('datecreation', file.lastModified)
    formData.append('path', path.value)
    formData.append('type_mime', file.type)
    formData.append('_action', 'create')
    const params = {
      url,
      method: 'POST',
      data: formData,
      onUploadProgress: function (progressEvent) {
        const { loaded, total } = progressEvent
        percentage.value = Math.floor((loaded * 100) / total)
      }
    }
    percentage.value = 0
    loading.value = true
    let request
    try {
      request = await axios(params)
      if (request.status === 201) {
        loading.value = false
        loadingIndex.value = true
        await websock.waitForJournal(datasetId, 'finalize-end')
        execute()
        loadingIndex.value = false
      }
    } catch (e) {
      errorMessage.value = e.message
      displayError.value = true
      loading.value = false
      loadingIndex.value = false
    }
  } else if (file === null) { // we post a folder
    const doc = {
      nom,
      path: path.value,
      _action: 'create',
      type_mime: '_folder'
    }
    const params = {
      method: 'POST',
      body: JSON.stringify(doc),
      headers: {
        'Content-type': 'application/json'
      }
    }
    try {
      const request = await fetch(url, params)
      if (request.status === 201) {
        loadingIndex.value = true
        await websock.waitForJournal(datasetId, 'finalize-end')
        execute()
        loadingIndex.value = false
      }
    } catch (e) {
      errorMessage.value = e.message
      displayError.value = true
      loadingIndex.value = false
    }
  } else {
    errorMessage.value = 'Erreur : Fichier trop volumineux, la taille doit être inférieure à 5 Mo'
    displayError.value = true
  }
}
// method : post all the files from the drag and drop zone
export async function postFilesDD (filesInput) {
  const files = []
  for (let i = 0; i < filesInput.length; i++) {
    files.push(filesInput.item(i))
  }
  const url = `${dataUrl}/lines`
  files.forEach(async (file) => {
    if (file.size === 0) { // we post a folder
      const doc = {
        nom: file.name,
        path: path.value,
        _action: 'create',
        type_mime: '_folder'
      }
      const params = {
        method: 'POST',
        body: JSON.stringify(doc),
        headers: {
          'Content-type': 'application/json'
        }
      }
      try {
        const request = await fetch(url, params)
        if (request.status === 201) {
          // const reponse = await request.json()
        }
      } catch (e) {
        errorMessage.value = e.response.status + ' : ' + e.response.data
        displayError.value = true
      }
    } else if (file.size < 5000000) { // we post a file
      const formData = new FormData()
      formData.append('attachment', file)
      formData.append('nom', file.name)
      formData.append('nbrevisions', 1)
      formData.append('taille', file.size)
      formData.append('datecreation', file.lastModified)
      formData.append('path', path.value)
      formData.append('type_mime', file.type)
      formData.append('_action', 'create')
      const params = {
        url,
        method: 'POST',
        data: formData,
        onUploadProgress: function (progressEvent) {
          const { loaded, total } = progressEvent
          percentage.value = Math.floor((loaded * 100) / total)
        }
      }
      percentage.value = 0
      loading.value = true
      let request
      try {
        request = await axios(params)
        if (request.status === 201) {
          loading.value = false
        }
      } catch (e) {
        errorMessage.value = e.response.status + ' : ' + e.response.data
        displayError.value = true
        loading.value = false
      }
    } else {
      errorMessage.value = 'Erreur : Le fichier : ' + file.name + ' est trop volumineux (> 5Mo)'
      displayError.value = true
    }
  })
  try {
    await websock.waitForJournal(datasetId, 'finalize-end')
    execute()
  } catch (e) {
    errorMessage.value = e.message
    displayError.value = true
  }
}

// method : get all the versions of a file, sorted by modification date
export async function getRevisions (ligneId) {
  const url = `${dataUrl}/lines/${ligneId}/revisions`
  try {
    const request = await fetch(url)
    if (request.status === 200) {
      const reponse = await request.json()
      hmDisplay.value = reponse.results.reverse()
      hmDisplay.value.forEach((value) => {
        const date = new Date(value._updatedAt)
        value._updatedAt = date.toLocaleString()
      })
    }
  } catch (e) {
    errorMessage.value = e.response.status + ' : ' + e.response.data
    displayError.value = true
  }
}
// method : delete file, API says to use bulk_lines to delete all of the versions of the file
export async function deleteFile (ligneId) {
  const url = `${dataUrl}/_bulk_lines`
  const doc = [{
    _action: 'delete',
    _id: ligneId
  }]
  const params = {
    method: 'POST',
    body: JSON.stringify(doc),
    headers: {
      'Content-type': 'application/json'
    }
  }
  try {
    const request = await fetch(url, params)
    if (request.ok) {
      loadingIndex.value = true
      await websock.waitForJournal(datasetId, 'finalize-end')
      execute()
      loadingIndex.value = false
    }
  } catch (e) {
    errorMessage.value = e.message
    displayError.value = true
    loadingIndex.value = false
  }
}
// method : delete folder and all of its dependencies (all files/folders contained in it), it uses trackDependencies function to recursive deletes
export async function deleteFolder (pathFolder, nameFolder, ligneId) {
  if (ligneId === nameFolder) { // it means that we delete a non empty folder
    const str = pathFolder + nameFolder + '/'
    const tmp = str.split('/')
    const p = tmp.join('\\/')
    const url = `${dataUrl}/lines?q_mode=complete&qs=(path:${p}*)`
    const params = {
      method: 'GET',
      headers: {
        'Content-type': 'application/json'
      }
    }
    try {
      const request = await fetch(url, params)
      if (request.ok) {
        const reponse = await request.json()
        reponse.results.forEach((value) => {
          deleteFile(value._id)
        })
      }
    } catch (e) {
      errorMessage.value = e.response.status + ' : ' + e.response.data
      displayError.value = true
    }
  } else { // we delete an empty folder with classic deleteFile method
    deleteFile(ligneId)
  }
}

// method : patch a data
// if folder, update the path and patch all its dependencies by patching them one by one
// if file : if we just change name we do a simple patch else we do a post with more parameters in the dataform (action, id and attachmentPath)
// API will understand and automatically update the file and store the old version in revsions (see more on DataFair API)
export async function patchDocument (id, payload, folder, chemin) {
  const { nom, file } = payload
  let url = `${dataUrl}/lines/`
  const data = dataset.value.get(id)
  const formData = new FormData()
  let request
  if (!folder) {
    if (file !== '' && file.size < 5000000) {
      formData.append('attachment', file)
      formData.append('nom', nom || data.nom)
      formData.append('nbrevisions', data.nbrevisions + 1)
      formData.append('datecreation', data.datecreation)
      formData.append('path', data.path)
      formData.append('taille', file.size)
      formData.append('type_mime', file.type)
      formData.append('_action', 'update')
      formData.append('_id', id)
      formData.append('attachmentPath', data.attachmentPath)
      const params = {
        url,
        method: 'POST',
        data: formData,
        onUploadProgress: function (progressEvent) {
          const { loaded, total } = progressEvent
          percentage.value = Math.floor((loaded * 100) / total)
        }
      }
      percentage.value = 0
      loading.value = true
      try {
        request = await axios(params)
        loading.value = false
        if (request.status === 200) {
          // reponse = request.data
          loading.value = false
          loadingIndex.value = true
          await websock.waitForJournal(datasetId, 'finalize-end')
          execute()
          loadingIndex.value = false
        }
      } catch (e) {
        errorMessage.value = e.message
        displayError.value = true
        loading.value = false
        loadingIndex.value = false
      }
    } else if (file === '') {
      url = `${dataUrl}/lines/${id}`
      formData.append('nom', nom || data.nom)
      const params = {
        method: 'PATCH',
        body: formData
      }
      try {
        const request = await fetch(url, params)
        if (request.status === 200) {
          loadingIndex.value = true
          await websock.waitForJournal(datasetId, 'finalize-end')
          execute()
          loadingIndex.value = false
        }
      } catch (e) {
        errorMessage.value = e.message
        displayError.value = true
        loadingIndex.value = false
      }
    } else {
      errorMessage.value = 'Fichier trop volumineux, taille > 5Mo'
      displayError.value = true
    }
  } else { // if we patch a folder
    const i = chemin.split('/').length - 1 // get the index of folder's name we change in the path
    const str = chemin + id + '/'
    const tmp = str.split('/')
    const p = tmp.join('\\/')
    const url = `${dataUrl}/lines?q_mode=complete&qs=(path:${p}*)`
    const params = {
      method: 'GET',
      headers: {
        'Content-type': 'application/json'
      }
    }
    try {
      const request = await fetch(url, params)
      if (request.ok) {
        const reponse = await request.json()
        reponse.results.forEach(async (value) => { // patch the path field
          let newpath = value.path.split('/')
          const fd = new FormData()
          newpath[i] = nom
          newpath = newpath.join('/')
          fd.append('path', newpath)
          const nurl = `${dataUrl}/lines/${value._id}`
          const params = {
            method: 'PATCH',
            body: fd
          }
          try {
            await fetch(nurl, params)
          } catch (e) {
            errorMessage.value = e.response.status + ' : ' + e.response.data
            displayError.value = true
          }
        })
      }
    } catch (e) {
      errorMessage.value = e.response.status + ' : ' + e.response.data
      displayError.value = true
    }
    try {
      loadingIndex.value = false
      await websock.waitForJournal(datasetId, 'finalize-end')
      execute()
      loadingIndex.value = false
    } catch (e) {
      errorMessage.value = e.message
      displayError.value = true
      loadingIndex.value = false
    }
  }
}

// method : download the old file by using the saveAs method from the file-saver npm package
// path (string) : _id/hash/name of the file we want to download
export async function downloadFile (pathD, name) {
  const url = `${dataUrl}/attachments/${pathD}`
  try {
    const request = await fetch(url)
    if (request.status === 200) {
      const reponse = await request.blob()
      saveAs(reponse, name)
    }
  } catch (e) {
    errorMessage.value = e.response.status + ' : ' + e.response.data
    displayError.value = true
  }
}
