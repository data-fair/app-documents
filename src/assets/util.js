import { ref, reactive } from 'vue'
import { saveAs } from 'file-saver'
import axios from 'axios'
import useAppInfo from '@/composables/useAppInfo'
import useServerInfo from '@/composables/useWSClient.js'
import { execute, path, data } from '../context.js'
const { dataUrl, datasetId, wsUrl } = useAppInfo()
const websock = useServerInfo(wsUrl) // handle and listen the websocket to have info when data-fair finished indexing data
export const hmDisplay = ref([]) // display history of modification of selected file (see revisions)
export const loading = ref(false) // show a progress bar when uploading a file
export const loadingIndex = ref(false) // show a progress bar when data-fair is indexing the file
export const percentage = ref(0) // value of the progress bar loading
export const displayError = ref(false) // display error v-snackbar if error on requests
export const errorMessage = ref('') // error message to display
export const payloadDocument = reactive({
  nom: '',
  file: ''
})
// method : post the document generated by the button
export async function postDocument (payload) {
  const { nom, file } = payload
  const url = `${dataUrl}/lines`
  if (file !== null && file.size < 5000000) { // we post a file
    if (path.value !== '/') { // first, check if the data we post is the first value of a fodler, if yes delete the folder in the data
      const tmp = path.value.split('/')
      tmp.pop()
      const name = tmp.pop()
      tmp.push('')
      const str = tmp.join('\\/')
      const p = encodeURIComponent('path:/' + str + '/')
      const url2 = `${dataUrl}/lines?q=${name}&q_fields=nom&q_mode=simple&qs=${p} and type_mime:"_folder"`
      const request = await fetch(url2)
      if (request.ok) {
        const rep = await request.json()
        if (rep.results[0] !== undefined) {
          const id = rep.results[0]._id
          const url = `${dataUrl}/lines/${id}`
          const params = {
            method: 'DELETE',
            headers: {
              'Content-type': 'application/json'
            }
          }
          try {
            await fetch(url, params)
          } catch (e) {
            errorMessage.value = e.response.status + ' : ' + e.response.data
            displayError.value = true
          }
        }
      }
    }
    const formData = new FormData()
    formData.append('attachment', file)
    formData.append('nom', nom || file.name)
    formData.append('nbrevisions', 1)
    formData.append('taille', file.size)
    const date = new Date(file.lastModified)
    formData.append('datecreation', date.toISOString())
    formData.append('datemodification', date.toISOString())
    formData.append('path', path.value)
    formData.append('type_mime', file.type)
    formData.append('_action', 'create')
    const params = {
      url,
      method: 'POST',
      data: formData,
      onUploadProgress: function (progressEvent) {
        const { loaded, total } = progressEvent
        percentage.value = Math.floor((loaded * 100) / total)
      }
    }
    percentage.value = 0
    loading.value = true
    let request
    try {
      // check if the file is already present in the current folder
      data.value.forEach((value, key) => {
        if (value.attachmentPath !== undefined) {
          const tmp = value.attachmentPath.split('/').pop()
          const tmp2 = new Date(file.lastModified)
          if (tmp === file.name && tmp2.toISOString() === value.datemodification) {
            throw new Error('Erreur : le fichier est deja présent : ' + value.nom)
          }
        }
      })
      request = await axios(params)
      if (request.status === 201) {
        loading.value = false
        loadingIndex.value = true
        await websock.waitForJournal(datasetId)
        execute()
        loadingIndex.value = false
      }
    } catch (e) {
      errorMessage.value = e.message
      displayError.value = true
      loading.value = false
      loadingIndex.value = false
    }
  } else if (file === null) { // we post a folder
    const doc = {
      nom,
      path: path.value,
      _action: 'create',
      type_mime: '_folder'
    }
    const params = {
      method: 'POST',
      body: JSON.stringify(doc),
      headers: {
        'Content-type': 'application/json'
      }
    }
    try {
      const request = await fetch(url, params)
      if (request.status === 201) {
        loadingIndex.value = true
        await websock.waitForJournal(datasetId)
        execute()
        loadingIndex.value = false
      }
    } catch (e) {
      errorMessage.value = e.message
      displayError.value = true
      loadingIndex.value = false
    }
  } else {
    errorMessage.value = 'Erreur : Fichier trop volumineux, la taille doit être inférieure à 5 Mo'
    displayError.value = true
  }
}
// method : post all the files from the drag and drop zone
export async function postFilesDD (filesInput) {
  const files = []
  for (let i = 0; i < filesInput.length; i++) {
    files.push(filesInput.item(i))
  }
  const url = `${dataUrl}/lines`
  files.forEach(async (file) => {
    if (file.size === 0) { // we post a folder
      const doc = {
        nom: file.name,
        path: path.value,
        _action: 'create',
        type_mime: '_folder'
      }
      const params = {
        method: 'POST',
        body: JSON.stringify(doc),
        headers: {
          'Content-type': 'application/json'
        }
      }
      try {
        const request = await fetch(url, params)
        if (request.status === 201) {
          // const reponse = await request.json()
        }
      } catch (e) {
        errorMessage.value = e.response.status + ' : ' + e.response.data
        displayError.value = true
      }
    } else if (file.size < 5000000) { // we post a file
      const formData = new FormData()
      formData.append('attachment', file)
      formData.append('nom', file.name)
      formData.append('nbrevisions', 1)
      formData.append('taille', file.size)
      const date = new Date(file.lastModified)
      formData.append('datecreation', date.toISOString())
      formData.append('datemodification', date.toISOString())
      formData.append('path', path.value)
      formData.append('type_mime', file.type)
      formData.append('_action', 'create')
      const params = {
        url,
        method: 'POST',
        data: formData,
        onUploadProgress: function (progressEvent) {
          const { loaded, total } = progressEvent
          percentage.value = Math.floor((loaded * 100) / total)
        }
      }
      percentage.value = 0
      loading.value = true
      let request
      try {
        data.value.forEach((value, key) => {
          if (value.attachmentPath !== undefined) {
            const tmp = value.attachmentPath.split('/').pop()
            const tmp2 = new Date(file.lastModified)
            if (tmp === file.name && tmp2.toISOString() === value.datemodification) {
              throw new Error('Erreur : le fichier est deja présent : ' + value.nom)
            }
          }
        })
        request = await axios(params)
        if (request.status === 201) {
          loading.value = false
        }
      } catch (e) {
        console.log(e)
        errorMessage.value = e.message || e.response.status + ' : ' + e.response.data
        displayError.value = true
        loading.value = false
      }
    } else {
      errorMessage.value = 'Erreur : Le fichier : ' + file.name + ' est trop volumineux (> 5Mo)'
      displayError.value = true
    }
  })
  try {
    loadingIndex.value = true
    await websock.waitForJournal(datasetId)
    loadingIndex.value = false
    execute()
  } catch (e) {
    errorMessage.value = e.message
    displayError.value = true
    loadingIndex.value = false
  }
}
// method : get all the versions of a file, sorted by modification date
export async function getRevisions (ligneId) {
  const url = `${dataUrl}/lines/${ligneId}/revisions`
  try {
    const request = await fetch(url)
    if (request.status === 200) {
      const reponse = await request.json()
      hmDisplay.value = reponse.results
      hmDisplay.value.forEach((value) => {
        const date = new Date(value.datemodification) // just display a better date format
        value.datemodification = date.toLocaleString()
      })
    }
  } catch (e) {
    errorMessage.value = e.response.status + ' : ' + e.response.data
    displayError.value = true
  }
}
// method : delete file, API says to use _bulk_lines to delete all of the versions of the file
export async function deleteFile (ligneId) {
  const url = `${dataUrl}/_bulk_lines`
  const doc = [{
    _action: 'delete',
    _id: ligneId
  }]
  const params = {
    method: 'POST',
    body: JSON.stringify(doc),
    headers: {
      'Content-type': 'application/json'
    }
  }
  try {
    const request = await fetch(url, params)
    if (request.ok) {
      loadingIndex.value = true
      await websock.waitForJournal(datasetId)
      await execute()
      loadingIndex.value = false
    }
  } catch (e) {
    errorMessage.value = e.message
    displayError.value = true
    loadingIndex.value = false
  }
}
// method : delete folder and all of its dependencies (all files/folders contained in it)
export async function deleteFolder (pathFolder, nameFolder, ligneId) {
  if (ligneId === nameFolder) { // it means that we delete a non empty folder
    const str = pathFolder + nameFolder + '/'
    const tmp = str.split('/')
    const p = tmp.join('\\/')
    const url = `${dataUrl}/lines?q_mode=complete&qs=(path:${p}*)`
    const params = {
      method: 'GET',
      headers: {
        'Content-type': 'application/json'
      }
    }
    try {
      const request = await fetch(url, params)
      if (request.ok) {
        const reponse = await request.json()
        reponse.results.forEach((value) => {
          deleteFile(value._id)
        })
      }
    } catch (e) {
      errorMessage.value = e.response.status + ' : ' + e.response.data
      displayError.value = true
    }
  } else { // we delete an empty folder with classic deleteFile method
    deleteFile(ligneId)
  }
}
// method : patch a data
// if folder, update the path and patch all its dependencies by patching them one by one
// if file : if we just change name we do a simple patch else we do a post with more parameters in the dataform (_action, _id and attachmentPath)
// API will understand and automatically update the file and store the old version in revisions (see more on DataFair API)
export async function patchDocument (id, payload, folder, chemin) {
  const { nom, file } = payload
  let url = `${dataUrl}/lines/`
  const line = data.value.get(id)
  const formData = new FormData()
  let request
  if (!folder) {
    if (file !== '' && file.size < 5000000) {
      formData.append('attachment', file)
      formData.append('nom', nom || line.nom)
      formData.append('nbrevisions', line.nbrevisions + 1)
      formData.append('datecreation', line.datecreation)
      const date = new Date(file.lastModified)
      formData.append('datemodification', date.toISOString())
      formData.append('path', line.path)
      formData.append('taille', file.size)
      formData.append('type_mime', file.type)
      formData.append('_action', 'update')
      formData.append('_id', id)
      formData.append('attachmentPath', line.attachmentPath)
      const params = {
        url,
        method: 'POST',
        data: formData,
        onUploadProgress: function (progressEvent) {
          const { loaded, total } = progressEvent
          percentage.value = Math.floor((loaded * 100) / total)
        }
      }
      percentage.value = 0
      loading.value = true
      try {
        if (date.toISOString() === line.datemodification) {
          throw new Error('Erreur : Le fichier n\' a pas été modifié')
        }
        request = await axios(params)
        loading.value = false
        if (request.status === 200) {
          loading.value = false
          loadingIndex.value = true
          await websock.waitForJournal(datasetId)
          execute()
          loadingIndex.value = false
        }
      } catch (e) {
        errorMessage.value = e.message
        displayError.value = true
        loading.value = false
        loadingIndex.value = false
      }
    } else if (file === '') {
      url = `${dataUrl}/lines/${id}`
      formData.append('nom', nom || line.nom)
      const params = {
        method: 'PATCH',
        body: formData
      }
      try {
        const request = await fetch(url, params)
        if (request.status === 200) {
          loadingIndex.value = true
          await websock.waitForJournal(datasetId)
          execute()
          loadingIndex.value = false
        }
      } catch (e) {
        errorMessage.value = e.message
        displayError.value = true
        loadingIndex.value = false
      }
    } else {
      errorMessage.value = 'Fichier trop volumineux, taille > 5Mo'
      displayError.value = true
    }
  } else { // if we patch a folder
    const i = chemin.split('/').length - 1 // get the index of folder's name we change in the path
    const str = chemin + id + '/'
    const tmp = str.split('/')
    const p = tmp.join('\\/')
    const url = `${dataUrl}/lines?q_mode=complete&qs=(path:${p}*)`
    const params = {
      method: 'GET',
      headers: {
        'Content-type': 'application/json'
      }
    }
    try {
      const request = await fetch(url, params)
      if (request.ok) {
        const reponse = await request.json()
        reponse.results.forEach(async (value) => { // patch the path field
          let newpath = value.path.split('/')
          const fd = new FormData()
          newpath[i] = nom
          newpath = newpath.join('/')
          fd.append('path', newpath)
          const nurl = `${dataUrl}/lines/${value._id}`
          const params = {
            method: 'PATCH',
            body: fd
          }
          try {
            await fetch(nurl, params)
          } catch (e) {
            errorMessage.value = e.response.status + ' : ' + e.response.data
            displayError.value = true
          }
        })
      }
    } catch (e) {
      errorMessage.value = e.response.status + ' : ' + e.response.data
      displayError.value = true
    }
    try {
      loadingIndex.value = true
      await websock.waitForJournal(datasetId)
      execute()
      loadingIndex.value = false
    } catch (e) {
      errorMessage.value = e.message
      displayError.value = true
      loadingIndex.value = false
    }
  }
}
// method : download the old file by using the saveAs method from the file-saver npm package
// pathD (string) : _id/hash/name of the file to download -> attachmentPath field
export async function downloadFile (pathD, name) {
  const url = `${dataUrl}/attachments/${pathD}`
  try {
    const request = await fetch(url)
    if (request.status === 200) {
      const reponse = await request.blob()
      saveAs(reponse, name)
    }
  } catch (e) {
    errorMessage.value = e.response.status + ' : ' + e.response.data
    displayError.value = true
  }
}
